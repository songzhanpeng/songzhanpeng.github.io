import{_ as s,c as a,o as e,V as p}from"./chunks/framework.ad474ad6.js";const u=JSON.parse('{"title":"使用whisper生成字幕","description":"使用whisper生成字幕","frontmatter":{"title":"使用whisper生成字幕","description":"使用whisper生成字幕","date":"2023-03-22T00:00:00.000Z","tags":["工具"]},"headers":[],"relativePath":"posts/使用whisper生成字幕.md"}'),l={name:"posts/使用whisper生成字幕.md"},n=p(`<h2 id="简介" tabindex="-1">简介 <a class="header-anchor" href="#简介" aria-label="Permalink to &quot;简介&quot;">​</a></h2><p>whisper 是 openai 开源的字幕识别工具，可以识别字幕，翻译字幕，因为他英文翻译中文的效果一般，所以我一般就用它识别英文字幕</p><h2 id="安装步骤" tabindex="-1">安装步骤 <a class="header-anchor" href="#安装步骤" aria-label="Permalink to &quot;安装步骤&quot;">​</a></h2><blockquote><p>下面这些步骤基于 m1 pro</p></blockquote><h3 id="安装-python" tabindex="-1">安装 python <a class="header-anchor" href="#安装-python" aria-label="Permalink to &quot;安装 python&quot;">​</a></h3><p>在<a href="https://github.com/openai/whisper" target="_blank" rel="noreferrer">whisper 的 github</a>找到对应的 python 版本，目前是 3.9.9，然后去 python 官网下载对应版本的安装器安装即可</p><h3 id="安装-ffmper" tabindex="-1">安装 ffmper <a class="header-anchor" href="#安装-ffmper" aria-label="Permalink to &quot;安装 ffmper&quot;">​</a></h3><div class="language-shell"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#676E95;font-style:italic;"># on MacOS using Homebrew (https://brew.sh/)</span></span>
<span class="line"><span style="color:#FFCB6B;">brew</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">install</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">ffmpeg</span></span></code></pre></div><h3 id="安装-whisper" tabindex="-1">安装 whisper <a class="header-anchor" href="#安装-whisper" aria-label="Permalink to &quot;安装 whisper&quot;">​</a></h3><div class="language-shell"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#FFCB6B;">pip</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">install</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">-U</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">openai-whisper</span></span></code></pre></div><p>这个时候 whisper 就可以用了，使用 help 查看可选命令</p><div class="language-shell"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#FFCB6B;">whisper</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">--help</span></span></code></pre></div><div class="language-shell"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#FFCB6B;">--language</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">en</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">是指生成英文字幕</span></span>
<span class="line"><span style="color:#FFCB6B;">--task</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">transcribe</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">是指生成字幕，translate是翻译字幕</span></span>
<span class="line"><span style="color:#FFCB6B;">--model</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">medium.en</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">是指用medium.en这个model，还有small、tiny...可选</span></span>
<span class="line"><span style="color:#FFCB6B;">--output_format</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">srt</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">是指产物格式，不输入默认生成所有格式</span></span>
<span class="line"><span style="color:#FFCB6B;">--device</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">mps</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">是指用什么渲染，一般可选cuda、mps、cpu</span><span style="color:#89DDFF;">(</span><span style="color:#FFCB6B;">cuda是nvidia的gpu技术、mps是m1的gpu技术</span><span style="color:#89DDFF;">)</span></span></code></pre></div><p>当然，这个时候只能用基础功能的 whisper，默认使用 cpu 渲染，默认使用 small 模型</p><div class="language-shell"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#FFCB6B;">whisper</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">test.mp4</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">--language</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">en</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">--task</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">transcribe</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">--output_format</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">srt</span></span></code></pre></div><h3 id="进阶" tabindex="-1">进阶 <a class="header-anchor" href="#进阶" aria-label="Permalink to &quot;进阶&quot;">​</a></h3><h4 id="使用-medium-模型" tabindex="-1">使用 medium 模型 <a class="header-anchor" href="#使用-medium-模型" aria-label="Permalink to &quot;使用 medium 模型&quot;">​</a></h4><p>我们会发现，默认的 small 模型生成的字幕质量一般，所以我们想用 medium 模型，然而 whisper 在 m1 上自动下载 medium 模型的时候会报 ssl certificate 的错，这个时候我们可以手动下载来解决：</p><p>我们访问 <a href="https://github.com/openai/whisper/blob/main/whisper/__init__.py" target="_blank" rel="noreferrer">这个地址</a>来找到 medium.en 这个模型的下载地址，手动下载后，放入<code>/Users/{username}/.cache/whisper</code>目录里即可</p><div class="language-shell"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#FFCB6B;">whisper</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">test.mp4</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">--language</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">en</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">--task</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">transcribe</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">--model</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">medium.en</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">--output_format</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">srt</span></span></code></pre></div><blockquote><p>这个其实是 known issue,解决办法有两个，这里使用的第二种解决办法</p><ol><li><p><a href="https://github.com/openai/whisper/discussions/734#discussioncomment-4491761" target="_blank" rel="noreferrer">https://github.com/openai/whisper/discussions/734#discussioncomment-4491761</a></p></li><li><p><a href="https://github.com/openai/whisper/discussions/734#discussioncomment-4492259" target="_blank" rel="noreferrer">https://github.com/openai/whisper/discussions/734#discussioncomment-4492259</a></p></li></ol></blockquote><h4 id="使用-gpu-加快生成速度" tabindex="-1">使用 gpu 加快生成速度 <a class="header-anchor" href="#使用-gpu-加快生成速度" aria-label="Permalink to &quot;使用 gpu 加快生成速度&quot;">​</a></h4><p>我们会发现用 cpu 的生成速度慢的不行，whisper 是支持使用 gpu 生成的，gpu 的生成速度比 cpu 快不少，而且 nvidia 的 cuda 和苹果 m1 的 mps 都是性能很高的 gpu 渲染技术。</p><p>首先，我们需要安装 pytorch</p><div class="language-shell"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#FFCB6B;">pip3</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">install</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">torch</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">torchvision</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">torchaudio</span></span></code></pre></div><p>然后我们就可以在 m1 芯片的笔记本上使用 mps 渲染了吗?</p><div class="language-shell"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#FFCB6B;">whisper</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">test.mp4</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">--language</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">en</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">--task</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">transcribe</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">--model</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">medium.en</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">--output_format</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">srt</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">--device</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">mps</span></span></code></pre></div><p>哈哈，天真，报错啦！</p><p>大概看了一下，就是 whisper+pytorch+m1 的 mps 现在基本等于不可用，有人说安装最新 nightly 版本的 pytorch 可以解决，然而并没有</p><p>目前普遍的解决方案是使用<a href="https://github.com/ggerganov/whisper.cpp" target="_blank" rel="noreferrer">cpp 版本的 whisper</a>,这里我就不折腾了，用 cpu 就用 cpu 吧，慢一点又不是不能用...如果真的有需要大批量的翻译字幕，还是用 pc+nvidia 的显卡比较靠谱</p><h4 id="总结" tabindex="-1">总结 <a class="header-anchor" href="#总结" aria-label="Permalink to &quot;总结&quot;">​</a></h4><div class="language-shell"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#FFCB6B;">whisper</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">test.mp4</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">--language</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">en</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">--task</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">transcribe</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">--model</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">medium.en</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">--output_format</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">srt</span></span></code></pre></div><h3 id="备注" tabindex="-1">备注 <a class="header-anchor" href="#备注" aria-label="Permalink to &quot;备注&quot;">​</a></h3><p>上面生成了英文字幕，如果想要中文字幕，或者中英双语字幕，那么可以使用<a href="https://www.nikse.dk/subtitleedit/online" target="_blank" rel="noreferrer">免费机翻</a>,生成中文字幕后，下载下来，再使用字幕合成工具，把中英文合二为一,可以<a href="https://sspai.com/post/76899" target="_blank" rel="noreferrer">参考这里</a></p><p>不过，上面这种方式翻译质量堪忧，目前翻译质量比较好的还是 deepl 和 gpt，deepl 和 gpt 都需要付费，我觉得有英文字幕就行了吧，不懂的单词现查，就当作学英语了</p><p>或许有人会有疑问，为啥不用 whisper 的 translate 功能？主要有 2 个原因，第一是慢，第二是 medium 模型的中文翻译水平比较一般，如果需要中文翻译的话，还是使用别的翻译软件比较靠谱，比如上文提到的 deepl 和 gpt。当然，如果你的 pc 性能足够的话，也可以直接运行最新的 large-2 模型，中文翻译质量应该高不少</p>`,36),o=[n];function t(r,c,i,C,h,y){return e(),a("div",null,o)}const D=s(l,[["render",t]]);export{u as __pageData,D as default};
